DROP SCHEMA IF EXISTS dataset CASCADE; -- danger when reusing

CREATE SCHEMA dataset;

-- -- -- --
-- VALIDATION-CHECK functions
CREATE FUNCTION dataset.makekx_urn(p_name text,p_namespace text DEFAULT '') RETURNS text AS $f$
	SELECT CASE
			WHEN $2='' OR $2 IS NULL THEN $1
			ELSE lower($2)||':'||$1
	END
$f$ LANGUAGE SQL IMMUTABLE;
CREATE FUNCTION dataset.makekx_uname(p_uname text) RETURNS text AS $f$
	SELECT  lower(lib.normalizeterm($1))
$f$ LANGUAGE SQL IMMUTABLE;

-- -- -- --
-- -- Tables

CREATE TABLE dataset.ns(
  -- Namespace
  nsid  serial NOT NULL PRIMARY KEY,
  name text NOT NULL,  -- namespace label
  dft_lang text,  -- default lang of datasets
  jinfo JSONB,    -- any metadata as description, etc.
  created date DEFAULT now(),
  UNIQUE(name)
);
INSERT INTO dataset.ns (name) VALUES (''); -- the default namespace!

-- DROP TABLE IF EXISTS dataset.meta CASCADE;
CREATE TABLE dataset.meta (
	id serial PRIMARY KEY,
	namespace text NOT NULL DEFAULT '',  --  empty namespace is the main one, like 'public'
	name text NOT NULL, -- original dataset name or filename of the CSV

  is_canonic BOOLEAN DEFAULT false, -- for canonic or "reference datasets". Curated by community.
  sametypes_as text,  -- kx_urn of an is_canonic-dataset with same kx_types. For merge() or UNION.
	projection_of text, -- kx_urn of its is_canonic-dataset, need to map same kx_types. No canonic is a projection.

	info JSONb, -- all metadata (information) here!

	-- Cache fields generated by UPDATE or trigger.
	kx_uname text, -- the normalized name, used for  dataset.meta_id() and SQL-View labels
	kx_urn text,   -- the transparent ID for this dataset.  "$namespace:$kx_uname".
	kx_fields text[], -- field names as in info.
	kx_types text[],  -- field JSON-datatypes as in info.

	UNIQUE(namespace,kx_uname), -- not need but same as kx_urn
  CHECK( lib.normalizeterm(namespace)=namespace AND lower(namespace)=namespace ),
	CHECK( kx_uname=dataset.makekx_uname(name) ),
	CHECK( kx_urn=dataset.makekx_urn(kx_urn,namespace) ),
	CHECK( NOT(is_canonic) OR (is_canonic AND projection_of IS NULL) )
);

-- DROP TABLE IF EXISTS dataset.big CASCADE;
CREATE TABLE dataset.big (
  id bigserial not null primary key,
  source int NOT NULL REFERENCES dataset.meta(id) ON DELETE CASCADE, -- Dataset ID and metadata.
  key text,  -- Optional. Dataset primary key (converted to text).
  c JSONb CHECK(jsonb_array_length(c)>0), -- All dataset columns here, as exact copy of CSV line!
  UNIQUE(source,key)
);

-- -- --
-- -- --
-- Essential functions

CREATE FUNCTION dataset.meta_id(text,text DEFAULT NULL) RETURNS int AS $f$
	SELECT id
	FROM dataset.meta
	WHERE (CASE WHEN $2 IS NULL THEN kx_urn=$1 ELSE kx_uname=$1 AND namespace=$2 END)
$f$ LANGUAGE SQL IMMUTABLE;

CREATE or replace FUNCTION dataset.viewname(p_dataset_id int, istab boolean=false) RETURNS text AS $f$
	-- under construction!
  SELECT CASE WHEN $2 THEN 'tmpcsv_' ELSE 'vw_' END|| kx_uname FROM dataset.meta WHERE id=$1;
$f$ language SQL IMMUTABLE;

CREATE or replace FUNCTION dataset.viewname(text,text DEFAULT NULL,boolean DEFAULT false) RETURNS text AS $f$
	SELECT dataset.viewname(id,$3)
	FROM dataset.meta
	WHERE (CASE WHEN $2 IS NULL THEN kx_urn=$1 ELSE kx_uname=$1 AND namespace=$2 END)
$f$ LANGUAGE SQL IMMUTABLE;

/*
CREATE FUNCTION dataset.namespace_mv(p_newname text) RETURNS void AS $f$
	-- if not conflickt at dataset.meta ... rename
$f$ LANGUAGE SQL;
*/

CREATE or replace FUNCTION dataset.meta_refresh() RETURNS TRIGGER AS $f$
BEGIN
	IF NOT EXISTS (SELECT 1 FROM dataset.ns WHERE name = NEW.namespace) THEN
		RAISE EXCEPTION '(under construction) Invalid namespace: %', NEW.namespace;
	END IF; -- future = controlling here the namespaces and kx_ns.
	NEW.kx_uname := dataset.makekx_uname(NEW.name);
	NEW.kx_urn   := dataset.makekx_urn(NEW.kx_uname,NEW.namespace);
	IF NEW.info IS NOT NULL THEN
	 	NEW.kx_fields := dataset.metaget_schema_field(NEW.info,'name');
		NEW.kx_types  := dataset.metaget_schema_field(NEW.info,'type');
	END IF;
	RETURN NEW;
END;
$f$ LANGUAGE plpgsql;

-- -- --
-- -- --
-- Triggers
CREATE TRIGGER dataset_meta_kx  BEFORE INSERT OR UPDATE
    ON dataset.meta
		FOR EACH ROW EXECUTE PROCEDURE dataset.meta_refresh()
;

-- -- --
-- -- --
-- VIEWS
-- (name convention: "vw_" prefix for dataset-view, "v" prefix for main structure)


CREATE VIEW dataset.vmeta_summary_aux AS
  SELECT m.id, m.kx_urn as urn, m.info->'primaryKey' as pkey, m.info->>'lang' as lang,
    jsonb_array_length(m.info#>'{schema,fields}') as n_cols, t.n_rows
    -- jsonb_pretty(info) as show_info
  FROM dataset.meta m,
	LATERAL  (SELECT count(*) as n_rows FROM dataset.big WHERE source=m.id) t
;
CREATE VIEW dataset.vmeta_summary AS
  SELECT id, urn, pkey::text, lang, n_cols, n_rows
	FROM dataset.vmeta_summary_aux
;
CREATE VIEW dataset.vjmeta_summary AS
  SELECT jsonb_agg(to_jsonb(v)) AS jmeta_summary
	FROM dataset.vmeta_summary_aux v
;

CREATE VIEW dataset.vmeta_fields AS
  SELECT id, urn, f->>'name' as field_name, f->>'type' as field_type,
         f->>'description' as field_desc
  FROM (
    SELECT id, kx_urn as urn, jsonb_array_elements(info#>'{schema,fields}') as f
    FROM dataset.meta
  ) t
;
CREATE VIEW dataset.vjmeta_fields AS
  -- use SELECT jsonb_agg(jmeta_fields) as j FROM dataset.vjmeta_fields WHERE dataset_id IN (1,3);
	SELECT id AS dataset_id,
	  jsonb_build_object('dataset', dataset, 'fields', json_agg(field)) AS jmeta_fields
	FROM (
	  SELECT id,
		     jsonb_build_object('id',id, 'urn',urn) as dataset,
	       jsonb_build_object('field_name',field_name, 'field_type',field_type, 'field_desc',field_desc) as field
	  FROM dataset.vmeta_fields
	) t
	GROUP BY id, dataset
;


-- -- --
-- -- --
-- LIB for dataset-schema structures, toolkit.


/**
 * Get metadata pieces and transforms it into text-array.
 * Used in cache-refresh etc.
 */
CREATE FUNCTION dataset.metaget_schema_field(
  p_info JSONb, p_field text
) RETURNS text[] AS $f$
  SELECT array_agg(x)
  FROM (  -- need to "cast" from record to table, to use array_agg
    SELECT (jsonb_array_elements($1#>'{schema,fields}')->>p_field)::text
  ) t(x)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.metaget_schema_field(
  p_id int, p_field text
) RETURNS text[] AS $f$
  SELECT dataset.metaget_schema_field(info,$2)
  FROM  dataset.meta
  WHERE id=$1 --kx_urn=$1
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.metaget_schema_field(text, text, text DEFAULT NULL) RETURNS text[] AS $wrap$
  SELECT dataset.metaget_schema_field( dataset.meta_id($1,$3), $2 )
$wrap$ language SQL IMMUTABLE;

/**
 * Float-Sum of a slice of columns of the table dataset.big, avoiding nulls.
 */
CREATE FUNCTION dataset.fltsum_colslice(
  p_j JSONb,   -- from dataset.big.c
  p_ini int DEFAULT 0,  -- first column of the slice, starting with 0
  p_fim int DEFAULT NULL  -- last column of the slice, NULL for all cols
) RETURNS float  AS $f$
DECLARE
     i int;
     tsum float :=0.0;
BEGIN
  IF p_fim IS NULL OR p_fim<0 THEN p_fim:=jsonb_array_length($1); END IF;
  FOR i IN p_ini..p_fim LOOP
     tsum := tsum + COALESCE( ($1->>i)::float, 0 );
  END LOOP;
  RETURN tsum;
END;
$f$ LANGUAGE plpgsql IMMUTABLE;

/**
 * Bigint-Sum of a slice of columns of the table dataset.big, avoiding nulls.
 */
CREATE FUNCTION dataset.intsum_colslice(
  p_j JSONb,   -- from dataset.big.c
  p_ini int DEFAULT 0,  -- first column of the slice, starting with 0
  p_fim int DEFAULT NULL  -- last column of the slice, NULL for all cols
) RETURNS bigint  AS $f$
DECLARE
     i int;
     tsum bigint :=0;
BEGIN
  IF p_fim IS NULL OR p_fim<0 THEN p_fim:=jsonb_array_length($1); END IF;
  FOR i IN p_ini..p_fim LOOP
     tsum := tsum + COALESCE( ($1->>i)::bigint, 0 );
  END LOOP;
  RETURN tsum;
END;
$f$ LANGUAGE plpgsql IMMUTABLE;



-- -- -- ------
-- JSONb

CREATE FUNCTION dataset.jsonb_arrays(int) RETURNS JSONb AS $f$
	SELECT jsonb_agg(x) FROM (
			SELECT to_jsonb(kx_fields) FROM dataset.meta WHERE id=$1
			UNION ALL
			(SELECT c FROM dataset.big WHERE source=$1)
		) t(x)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.jsonb_arrays(text, text default NULL) RETURNS JSONb AS $wrap$
  SELECT dataset.jsonb_arrays( dataset.meta_id($1,$2) )
$wrap$ language SQL IMMUTABLE;

-- --
CREATE FUNCTION dataset.jsonb_objects(int) RETURNS JSONb AS $f$
	SELECT jsonb_agg(jsonb_object(k,x))
	FROM
		(SELECT jsonb_array_totext(c) FROM dataset.big WHERE source=$1) b(x), -- ugly convertion, lost JSON datatype
		(SELECT kx_fields FROM dataset.meta WHERE id=$1) t(k)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.jsonb_objects(text, text default NULL) RETURNS JSONb AS $wrap$
  SELECT dataset.jsonb_objects( dataset.meta_id($1,$2) )
$wrap$ language SQL IMMUTABLE;

-- -- -- -- -- -- --
-- Export


CREATE FUNCTION dataset.copy_to(
	p_copyselect text, -- any select command
	p_filename text, -- as output
	p_tmp boolean DEFAULT true,  -- flag to use or not automatic '/tmp' as path
	p_copytype text DEFAULT ''   -- eg. 'CSV HEADER'
) RETURNS text AS $f$
DECLARE
  q_path text;
	vwname  text;
BEGIN
	p_filename := trim(p_filename);
	q_path := CASE WHEN $3 THEN '/tmp/'||$2 ELSE $2 END;
	EXECUTE format(
		E'COPY (%s) TO %L %s',
		p_copyselect, q_path, p_copytype
	);
	RETURN format(
		'Exported %L to %L%s',
		lib.msgcut(p_copyselect,50),
		q_path,
		CASE WHEN p_copytype>'' THEN ' as '||p_copytype ELSE '' END
	);
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.export_thing(
	p_dataset_id int,
	p_thing text DEFAULT '',  -- nothing = vname
	p_format text DEFAULT 'csv', -- csv, json-arrays or json-objs
	p_filename text DEFAULT NULL, -- as output
	p_tmp boolean DEFAULT true  -- flag to use or not automatic '/tmp' as path
) RETURNS text AS $f$
DECLARE
	vname text;
	aux text;
	aux2 text;
BEGIN
	IF p_thing IS NULL THEN p_thing=''; END IF;
	vname := dataset.viewname($1);
	p_filename := trim(p_filename);
	IF p_filename IS NULL OR p_filename='' THEN
		aux := regexp_replace(vname,'^vw(\d*)','out\1');
		p_filename:= aux || '.' || CASE WHEN p_format='csv' THEN 'csv' ELSE 'json' END;
	END IF;

	IF p_format='csv' THEN
		aux := CASE WHEN p_thing='' THEN 'dataset.'||vname ELSE p_thing END;
		aux := 'SELECT * FROM ' || aux;
	ELSEIF p_format='json-arrays' THEN
		aux := CASE WHEN p_thing='' THEN 'dataset.jsonb_arrays('|| $1 ||')' ELSE p_thing END;
	  aux := 'SELECT '||aux;
	ELSE -- json-objs
		aux := CASE WHEN p_thing='' THEN 'dataset.jsonb_objects('|| $1 ||')' ELSE p_thing END;
		aux := 'SELECT '||aux;
	END IF;
	RETURN dataset.copy_to(
		aux,
		p_filename,
		p_tmp,
		CASE WHEN p_format='csv' THEN 'CSV HEADER' ELSE '' END
	);
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.export_thing(
	p_urn text,  text DEFAULT '',  text DEFAULT 'csv',
	text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
	SELECT dataset.export_thing( dataset.meta_id($1), $2, $3, $4, $5)
$wrap$ language SQL IMMUTABLE;

--- CSV:
CREATE FUNCTION dataset.export_as_csv(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'csv', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_csv(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
	SELECT dataset.export_thing( $1, NULL, 'csv', $2, $3)
$wrap$ language SQL IMMUTABLE;

---- JSON ARRAYS:
CREATE FUNCTION dataset.export_as_jarrays(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-arrays', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_jarrays(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-arrays', $2, $3)
$wrap$ language SQL IMMUTABLE;

---- JSON OBJCTS:
CREATE FUNCTION dataset.export_as_jobjects(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-objs', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_jobjects(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-objs', $2, $3)
$wrap$ language SQL IMMUTABLE;


CREATE or replace FUNCTION dataset.copy_to(JSONb, p_filename text, boolean DEFAULT true) RETURNS text AS $f$
-- Is a WORKAROUND, but working fine.
DECLARE
	aux text;
BEGIN
	DROP TABLE IF EXISTS tmp_json_output;
  CREATE TEMPORARY TABLE tmp_json_output(info JSONb);
	INSERT INTO tmp_json_output(info) VALUES($1);
  SELECT dataset.copy_to('SELECT info FROM tmp_json_output LIMIT 1', $2, $3) INTO aux;
	DROP TABLE tmp_json_output;
	RETURN aux;
END
$f$ language PLpgSQL;


----------
-----------


CREATE or replace FUNCTION dataset.merge_into(
	p_from_id int,
	p_into_id int
) RETURNS text AS $f$
BEGIN
	IF (select kx_types from dataset.meta where id=$1) = (select kx_types from dataset.meta where id=$2) THEN
		UPDATE dataset.big
		SET source=p_into_id
		WHERE source=p_from_id;
		DELETE FROM dataset.meta WHERE id=p_from_id;
		RETURN 'ok';
	ELSE
		RETURN 'not same kx_types';
	END IF;
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.merge_into(  int[], int ) RETURNS text AS $wrap$
	SELECT dataset.merge_into(x,$2) FROM unnest($1) t(x)
$wrap$ language SQL;
CREATE or replace FUNCTION dataset.merge_into(  text, text ) RETURNS text AS $wrap$
	SELECT dataset.merge_into(dataset.meta_id($1), dataset.meta_id($2))
$wrap$ language SQL;
CREATE or replace FUNCTION dataset.merge_into(  text[], text ) RETURNS text AS $wrap$
	SELECT dataset.merge_into(x,$2) FROM unnest($1) t(x)
$wrap$ language SQL;

/**
 * Build SQL fragments for CREATE clauses.
 * @param p_dataset_id at dataset.meta
 * @return array[viewName, tabName, colItems, fieldTypeItens]
 */
CREATE or replace FUNCTION dataset.build_sql_names(p_dataset_id int) RETURNS text[] AS $f$
DECLARE
	vname text;
	tname text;
	i int;
	q_fields text[];
	q_types  text[];
	c_item   text[];
	flditem  text[];
	sqltype  text;
BEGIN
	vname := 'dataset.'||dataset.viewname($1);
	tname := dataset.viewname($1,true);
	SELECT lib.pg_varname(kx_fields), kx_types
	  INTO q_fields,                  q_types
	FROM dataset.meta WHERE id=$1;
	IF q_types IS NULL OR q_fields IS NULL THEN
		RAISE EXCEPTION 'No cache for view generation';
	END IF;
	FOR i IN 1..array_upper(q_fields,1) LOOP
		sqltype := lib.jtype_to_sql(q_types[i]);
		c_item[i] := ' (c->>'|| (i-1) || ')::'|| sqltype ||' AS '|| q_fields[i];
		flditem[i] := q_fields[i] ||' '|| sqltype;
	END LOOP;
	RETURN array[vname, tname, array_to_string(c_item,', '), array_to_string(flditem,', '), array_to_string(q_fields,', ')];
END
$f$ language PLpgSQL;


/**
 * EXECUTE SQL clauses for drop/create VIEWs and FOREIGN TABLEs.
 * @param p_dataset_id at dataset.meta
 * @return array[viewName, dropView, createView, FgnName, dropFgnTab, viewFgnTab]
 */
CREATE or replace FUNCTION dataset.create(
	p_dataset_id int,
	p_filename text DEFAULT '',
	p_useHeader boolean DEFAULT true,
	p_delimiter text DEFAULT ',',
	p_pkcols text  DEFAULT '',
	p_intoSelect text DEFAULT ''  -- add do-flags array for each execute (1..5).
) RETURNS text AS $f$
DECLARE
  p text[];
	i int;
	s text;
BEGIN
	p := dataset.build_sql_names($1); -- p1=vname, p2=tname, p3=c_itens, p4=tab_itens, P5=field_names
	FOR i IN 1..2 LOOP IF p[i]>'' AND relname_exists2(p[i]) THEN
			s := CASE WHEN i=1 THEN 'VIEW' ELSE 'FOREIGN TABLE' END;
			EXECUTE format('DROP %s %s CASCADE;', s, p[i]);
	END IF; END LOOP;

	EXECUTE format(
		'CREATE VIEW %s AS SELECT %s FROM dataset.big where source=%s ORDER BY id', p[1], p[3], $1
	);

	IF p_delimiter='' OR p_delimiter IS NULL THEN p_delimiter=','; END IF;
	EXECUTE format(
		'CREATE FOREIGN TABLE %s (%s) SERVER csv_files OPTIONS (filename %L, format %L, delimiter %L, header %L)',
		 p[2],  p[4], p_filename, 'csv', p_delimiter, p_useHeader::text
	);

	IF p_intoSelect='' OR p_intoSelect IS NULL THEN
		p_intoSelect:=format(
			'SELECT %s%s, jsonb_build_array(%s) FROM %s',
			$1, p_pkcols, p[5], p[2]);
	END IF;
	s:= CASE WHEN p_pkcols='' THEN '' ELSE ',key' END;
	EXECUTE format( 'INSERT INTO dataset.big(source%s,c)  %s', s, p_intoSelect );

	RETURN 'ok all created for id='||$1;
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.create(
	p_urn text, text DEFAULT '', boolean DEFAULT true, text DEFAULT ',', text  DEFAULT '', text  DEFAULT ''
) RETURNS text AS $wrap$
	SELECT dataset.create( dataset.meta_id($1), $2, $3, $4 )
$wrap$ language SQL IMMUTABLE;


/**
 * Merge two or more datasets in a new one with a new column with the dataset-id.
 */
CREATE or replace FUNCTION dataset.merge_tonew(
	-- include the dataset name as new column in the merge. Clones meta from first.
	p_ids int[],
	p_name text -- new dataset name
) RETURNS text AS $f$
DECLARE
  i int;
	first int;
	fist_types text[];
	rest int[];
	idnew int;
BEGIN
	first := p_ids[1];
	rest  := p_ids[2:array_upper(p_ids,1)];
	SELECT kx_types INTO fist_types FROM dataset.meta WHERE id=first;
	FOREACH i IN ARRAY rest LOOP
		IF fist_types != (SELECT kx_types FROM dataset.meta where id=i) THEN
			RETURN 'not same kx_types, see ids: '||first ||' and '||i;
		END IF;
	END LOOP;
	INSERT INTO dataset.meta(name,info) VALUES (p_name,(SELECT info FROM dataset.meta WHERE id=first));
	idnew := dataset.meta_id(p_name);
	-- basta fazer || [source]
	INSERT INTO dataset.big(source, c) SELECT idnew,c FROM dataset.big WHERE source = ANY($1);
	return 'criou o new!';
END
$f$ language PLpgSQL;
