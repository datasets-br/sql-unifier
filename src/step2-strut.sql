DROP SCHEMA IF EXISTS dataset CASCADE; -- danger when reusing

CREATE SCHEMA dataset;

-- -- -- --
-- VALIDATION-CHECK functions
CREATE FUNCTION dataset.makekx_urn(p_name text,p_namespace text DEFAULT '') RETURNS text AS $f$
	SELECT CASE
			WHEN $2='' OR $2 IS NULL THEN $1
			ELSE lower($2)||':'||$1
	END
$f$ LANGUAGE SQL IMMUTABLE;
CREATE FUNCTION dataset.makekx_uname(p_uname text) RETURNS text AS $f$
	SELECT  lower(lib.normalizeterm($1))
$f$ LANGUAGE SQL IMMUTABLE;

-- -- -- --
-- -- Tables

CREATE TABLE dataset.ns(
  -- Namespace
  nsid  serial NOT NULL PRIMARY KEY,
  name text NOT NULL,  -- namespace label
  dft_lang text,  -- default lang of datasets
  jinfo JSONB,    -- any metadata as description, etc.
  created date DEFAULT now(),
  UNIQUE(name)
);
INSERT INTO dataset.ns (name) VALUES (''); -- the default namespace!

-- DROP TABLE IF EXISTS dataset.meta CASCADE;
CREATE TABLE dataset.meta (
	id serial PRIMARY KEY,
	namespace text NOT NULL DEFAULT '',  --  empty namespace is the main one, like 'public'
	name text NOT NULL, -- original dataset name or filename of the CSV

  is_canonic BOOLEAN DEFAULT false, -- for canonic or "reference datasets". Curated by community.
  sametypes_as text,  -- kx_urn of an is_canonic-dataset with same kx_types. For merge() or UNION.
	projection_of text, -- kx_urn of its is_canonic-dataset, need to map same kx_types. No canonic is a projection.

	info JSONb, -- all metadata (information) here!

	-- Cache fields generated by UPDATE or trigger.
	kx_uname text, -- the normalized name, used for  dataset.meta_id() and SQL-View labels
	kx_urn text,   -- the transparent ID for this dataset.  "$namespace:$kx_uname".
	kx_fields text[], -- field names as in info.
	kx_types text[],  -- field JSON-datatypes as in info.

	UNIQUE(namespace,kx_uname), -- not need but same as kx_urn
  CHECK( lib.normalizeterm(namespace)=namespace AND lower(namespace)=namespace ),
	CHECK( kx_uname=dataset.makekx_uname(name) ),
	CHECK( kx_urn=dataset.makekx_urn(kx_urn,namespace) ),
	CHECK( NOT(is_canonic) OR (is_canonic AND projection_of IS NULL) )
);

-- DROP TABLE IF EXISTS dataset.big CASCADE;
CREATE TABLE dataset.big (
  id bigserial not null primary key,
  source int NOT NULL REFERENCES dataset.meta(id) ON DELETE CASCADE, -- Dataset ID and metadata.
  key text,  -- Optional. Dataset primary key (converted to text).
  c JSONb CHECK(jsonb_array_length(c)>0), -- All dataset columns here, as exact copy of CSV line!
  UNIQUE(source,key)
);

-- -- --
-- -- --
-- Essential functions

CREATE FUNCTION dataset.meta_id(text,text DEFAULT NULL) RETURNS int AS $f$
	SELECT id
	FROM dataset.meta
	WHERE (CASE WHEN $2 IS NULL THEN kx_urn=$1 ELSE kx_uname=$1 AND namespace=$2 END)
$f$ LANGUAGE SQL IMMUTABLE;

CREATE FUNCTION dataset.viewname(p_dataset_id int) RETURNS text AS $f$
	-- under construction!
  SELECT 'vw_'||kx_uname FROM dataset.meta WHERE id=$1;
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.viewname(text,text DEFAULT NULL) RETURNS text AS $f$
	SELECT dataset.viewname(id)
	FROM dataset.meta
	WHERE (CASE WHEN $2 IS NULL THEN kx_urn=$1 ELSE kx_uname=$1 AND namespace=$2 END)
$f$ LANGUAGE SQL IMMUTABLE;

/*
CREATE FUNCTION dataset.namespace_mv(p_newname text) RETURNS void AS $f$
	-- if not conflickt at dataset.meta ... rename
$f$ LANGUAGE SQL;
*/

CREATE or replace FUNCTION dataset.meta_refresh() RETURNS TRIGGER AS $f$
BEGIN
	IF NOT EXISTS (SELECT 1 FROM dataset.ns WHERE name = NEW.namespace) THEN
		RAISE EXCEPTION '(under construction) Invalid namespace: %', NEW.namespace;
	END IF; -- future = controlling here the namespaces and kx_ns.
	NEW.kx_uname := dataset.makekx_uname(NEW.name);
	NEW.kx_urn   := dataset.makekx_urn(NEW.kx_uname,NEW.namespace);
	IF NEW.info IS NOT NULL THEN
	 	NEW.kx_fields := dataset.metaget_schema_field(NEW.info,'name');
		NEW.kx_types  := dataset.metaget_schema_field(NEW.info,'type');
	END IF;
	RETURN NEW;
END;
$f$ LANGUAGE plpgsql;

-- -- --
-- -- --
-- Triggers
CREATE TRIGGER dataset_meta_kx  BEFORE INSERT OR UPDATE
    ON dataset.meta
		FOR EACH ROW EXECUTE PROCEDURE dataset.meta_refresh()
;

-- -- --
-- -- --
-- VIEWS
-- (name convention: "vw_" prefix for dataset-view, "v" prefix for main structure)


CREATE VIEW dataset.vmeta_summary_aux AS
  SELECT id, kx_urn as urn, info->'primaryKey' as pkey, info->>'lang' as lang,
    jsonb_array_length(info#>'{schema,fields}') as n_fields
    -- jsonb_pretty(info) as show_info
  FROM dataset.meta
;
CREATE VIEW dataset.vmeta_summary AS
  SELECT id, urn, pkey::text, lang, n_fields FROM dataset.vmeta_summary_aux
;
CREATE VIEW dataset.vjmeta_summary AS
  SELECT jsonb_agg(to_jsonb(v)) AS jmeta_summary
	FROM dataset.vmeta_summary_aux v
;

CREATE VIEW dataset.vmeta_fields AS
  SELECT id, urn, f->>'name' as field_name, f->>'type' as field_type,
         f->>'description' as field_desc
  FROM (
    SELECT id, kx_urn as urn, jsonb_array_elements(info#>'{schema,fields}') as f
    FROM dataset.meta
  ) t
;
CREATE VIEW dataset.vjmeta_fields AS
  -- use SELECT jsonb_agg(jmeta_fields) as j FROM dataset.vjmeta_fields WHERE dataset_id IN (1,3);
	SELECT id AS dataset_id,
	  jsonb_build_object('dataset', dataset, 'fields', json_agg(field)) AS jmeta_fields
	FROM (
	  SELECT id,
		     jsonb_build_object('id',id, 'urn',urn) as dataset,
	       jsonb_build_object('field_name',field_name, 'field_type',field_type, 'field_desc',field_desc) as field
	  FROM dataset.vmeta_fields
	) t
	GROUP BY id, dataset
;


-- -- --
-- -- --
-- LIB for dataset-schema structures, toolkit.


/**
 * Get metadata pieces and transforms it into text-array.
 * Used in cache-refresh etc.
 */
CREATE FUNCTION dataset.metaget_schema_field(
  p_info JSONb, p_field text
) RETURNS text[] AS $f$
  SELECT array_agg(x)
  FROM (  -- need to "cast" from record to table, to use array_agg
    SELECT (jsonb_array_elements($1#>'{schema,fields}')->>p_field)::text
  ) t(x)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.metaget_schema_field(
  p_id int, p_field text
) RETURNS text[] AS $f$
  SELECT dataset.metaget_schema_field(info,$2)
  FROM  dataset.meta
  WHERE id=$1 --kx_urn=$1
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.metaget_schema_field(text, text, text DEFAULT NULL) RETURNS text[] AS $wrap$
  SELECT dataset.metaget_schema_field( dataset.meta_id($1,$3), $2 )
$wrap$ language SQL IMMUTABLE;

/**
 * Float-Sum of a slice of columns of the table dataset.big, avoiding nulls.
 */
CREATE FUNCTION dataset.fltsum_colslice(
  p_j JSONb,   -- from dataset.big.c
  p_ini int DEFAULT 0,  -- first column of the slice, starting with 0
  p_fim int DEFAULT NULL  -- last column of the slice, NULL for all cols
) RETURNS float  AS $f$
DECLARE
     i int;
     tsum float :=0.0;
BEGIN
  IF p_fim IS NULL OR p_fim<0 THEN p_fim:=jsonb_array_length($1); END IF;
  FOR i IN p_ini..p_fim LOOP
     tsum := tsum + COALESCE( ($1->>i)::float, 0 );
  END LOOP;
  RETURN tsum;
END;
$f$ LANGUAGE plpgsql IMMUTABLE;

/**
 * Bigint-Sum of a slice of columns of the table dataset.big, avoiding nulls.
 */
CREATE FUNCTION dataset.intsum_colslice(
  p_j JSONb,   -- from dataset.big.c
  p_ini int DEFAULT 0,  -- first column of the slice, starting with 0
  p_fim int DEFAULT NULL  -- last column of the slice, NULL for all cols
) RETURNS bigint  AS $f$
DECLARE
     i int;
     tsum bigint :=0;
BEGIN
  IF p_fim IS NULL OR p_fim<0 THEN p_fim:=jsonb_array_length($1); END IF;
  FOR i IN p_ini..p_fim LOOP
     tsum := tsum + COALESCE( ($1->>i)::bigint, 0 );
  END LOOP;
  RETURN tsum;
END;
$f$ LANGUAGE plpgsql IMMUTABLE;



-- -- -- ------
-- JSONb

CREATE FUNCTION dataset.jsonb_arrays(int) RETURNS JSONb AS $f$
	SELECT jsonb_agg(x) FROM (
			SELECT to_jsonb(kx_fields) FROM dataset.meta WHERE id=$1
			UNION ALL
			(SELECT c FROM dataset.big WHERE source=$1)
		) t(x)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.jsonb_arrays(text, text default NULL) RETURNS JSONb AS $wrap$
  SELECT dataset.jsonb_arrays( dataset.meta_id($1,$2) )
$wrap$ language SQL IMMUTABLE;

-- --
CREATE FUNCTION dataset.jsonb_objects(int) RETURNS JSONb AS $f$
	SELECT jsonb_agg(jsonb_object(k,x))
	FROM
		(SELECT jsonb_array_totext(c) FROM dataset.big WHERE source=$1) b(x), -- ugly convertion, lost JSON datatype
		(SELECT kx_fields FROM dataset.meta WHERE id=$1) t(k)
$f$ language SQL IMMUTABLE;

CREATE FUNCTION dataset.jsonb_objects(text, text default NULL) RETURNS JSONb AS $wrap$
  SELECT dataset.jsonb_objects( dataset.meta_id($1,$2) )
$wrap$ language SQL IMMUTABLE;

-- -- -- -- -- -- --
-- Export


CREATE FUNCTION dataset.copy_to(
	p_copyselect text, -- any select command
	p_filename text, -- as output
	p_tmp boolean DEFAULT true,  -- flag to use or not automatic '/tmp' as path
	p_copytype text DEFAULT ''   -- eg. 'CSV HEADER'
) RETURNS text AS $f$
DECLARE
  q_path text;
	vwname  text;
BEGIN
	p_filename := trim(p_filename);
	q_path := CASE WHEN $3 THEN '/tmp/'||$2 ELSE $2 END;
	EXECUTE format(
		E'COPY (%s) TO %L %s',
		p_copyselect, q_path, p_copytype
	);
	RETURN format(
		'Exported %L to %L%s',
		lib.msgcut(p_copyselect,50),
		q_path,
		CASE WHEN p_copytype>'' THEN ' as '||p_copytype ELSE '' END
	);
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.export_thing(
	p_dataset_id int,
	p_thing text DEFAULT '',  -- nothing = vname
	p_format text DEFAULT 'csv', -- csv, json-arrays or json-objs
	p_filename text DEFAULT NULL, -- as output
	p_tmp boolean DEFAULT true  -- flag to use or not automatic '/tmp' as path
) RETURNS text AS $f$
DECLARE
	vname text;
	aux text;
	aux2 text;
BEGIN
	IF p_thing IS NULL THEN p_thing=''; END IF;
	vname := dataset.viewname($1);
	p_filename := trim(p_filename);
	IF p_filename IS NULL OR p_filename='' THEN
		aux := regexp_replace(vname,'^vw(\d*)','out\1');
		p_filename:= aux || '.' || CASE WHEN p_format='csv' THEN 'csv' ELSE 'json' END;
	END IF;

	IF p_format='csv' THEN
		aux := CASE WHEN p_thing='' THEN 'dataset.'||vname ELSE p_thing END;
		aux := 'SELECT * FROM ' || aux;
	ELSEIF p_format='json-arrays' THEN
		aux := CASE WHEN p_thing='' THEN 'dataset.jsonb_arrays('|| $1 ||')' ELSE p_thing END;
	  aux := 'SELECT '||aux;
	ELSE -- json-objs
		aux := CASE WHEN p_thing='' THEN 'dataset.jsonb_objects('|| $1 ||')' ELSE p_thing END;
		aux := 'SELECT '||aux;
	END IF;
	RETURN dataset.copy_to(
		aux,
		p_filename,
		p_tmp,
		CASE WHEN p_format='csv' THEN 'CSV HEADER' ELSE '' END
	);
END
$f$ language PLpgSQL;

CREATE or replace FUNCTION dataset.export_thing(
	p_urn text,  text DEFAULT '',  text DEFAULT 'csv',
	text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
	SELECT dataset.export_thing( dataset.meta_id($1), $2, $3, $4, $5)
$wrap$ language SQL IMMUTABLE;

--- CSV:
CREATE FUNCTION dataset.export_as_csv(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'csv', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_csv(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
	SELECT dataset.export_thing( $1, NULL, 'csv', $2, $3)
$wrap$ language SQL IMMUTABLE;

---- JSON ARRAYS:
CREATE FUNCTION dataset.export_as_jarrays(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-arrays', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_jarrays(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-arrays', $2, $3)
$wrap$ language SQL IMMUTABLE;

---- JSON OBJCTS:
CREATE FUNCTION dataset.export_as_jobjects(
	int, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-objs', $2, $3)
$wrap$ language SQL IMMUTABLE;
CREATE FUNCTION dataset.export_as_jobjects(
	text, p_filename text DEFAULT NULL, boolean DEFAULT true
) RETURNS text AS $wrap$
  SELECT dataset.export_thing( $1, NULL, 'json-objs', $2, $3)
$wrap$ language SQL IMMUTABLE;


CREATE or replace FUNCTION dataset.copy_to(JSONb, p_filename text, boolean DEFAULT true) RETURNS text AS $f$
-- Is a WORKAROUND, but working fine.
DECLARE
	aux text;
BEGIN
	DROP TABLE IF EXISTS tmp_json_output;
  CREATE TEMPORARY TABLE tmp_json_output(info JSONb);
	INSERT INTO tmp_json_output(info) VALUES($1);
  SELECT dataset.copy_to('SELECT info FROM tmp_json_output LIMIT 1', $2, $3) INTO aux;
	DROP TABLE tmp_json_output;
	RETURN aux;
END
$f$ language PLpgSQL;
